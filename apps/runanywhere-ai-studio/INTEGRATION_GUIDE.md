# RunAnywhere AI Studio - Integration Guide

## Executive Summary

**RunAnywhere AI Studio = Expo Go + RunAnywhere Native Libraries**

This is a **direct fork of Expo Go** with RunAnywhere SDK native binaries pre-bundled. Users get the exact same Expo Go experience, but with on-device AI capabilities.

---

## The Vision: Vibe Coding with On-Device AI

### How It Works (User Flow)

```
1. Developer on Replit/Cursor creates an Expo app
   â””â”€â”€ Adds: @runanywhere/core, @runanywhere/llamacpp, @runanywhere/onnx to package.json

2. Developer runs: npx expo start
   â””â”€â”€ Metro bundler shows QR code

3. User scans QR with RunAnywhere AI Studio (NOT Expo Go)
   â””â”€â”€ App loads from Metro bundler
   â””â”€â”€ RunAnywhere APIs work immediately (native binaries pre-bundled!)

4. Developer's app can call:
   â””â”€â”€ LlamaCpp.loadModel(), LlamaCpp.generate()
   â””â”€â”€ ONNX.loadModel(), ONNX.run()
   â””â”€â”€ All on-device, no cloud required
```

### Why This Works

| Scenario | Expo Go | RunAnywhere AI Studio |
|----------|---------|----------------------|
| Developer adds `@runanywhere/llamacpp` | âŒ Crashes - no native binary | âœ… Works - binary pre-bundled |
| Developer adds `expo-camera` | âœ… Works | âœ… Works (same Expo modules) |
| Scan QR code | âœ… Loads bundle | âœ… Loads bundle (same kernel) |
| Load GGUF model | âŒ Not possible | âœ… Native llama.cpp available |

---

## Changes Made to Expo Go

### 1. package.json
- Renamed from `@expo/home` to `@runanywhere/ai-studio`
- Added dependencies:
  - `@runanywhere/core: ^0.16.11`
  - `@runanywhere/llamacpp: ^0.16.11`
  - `@runanywhere/onnx: ^0.16.11`
  - `react-native-nitro-modules: ^0.31.10`

### 2. app.json
- Changed name to "RunAnywhere AI Studio"
- Changed bundle identifiers:
  - iOS: `dev.runanywhere.aistudio`
  - Android: `dev.runanywhere.aistudio`
- Changed scheme from `exp` to `runanywhere`

### 3. Android settings.gradle
Added module includes:
```groovy
include ':react-native-nitro-modules'
include ':runanywhere_core'
include ':runanywhere_llamacpp'
include ':runanywhere_onnx'
```

### 4. Android expoview/build.gradle
Added dependencies:
```groovy
implementation project(':react-native-nitro-modules')
implementation project(':runanywhere_core')
implementation project(':runanywhere_llamacpp')
implementation project(':runanywhere_onnx')
```

### 5. Android app/build.gradle
- Changed namespace to `dev.runanywhere.aistudio`
- Changed applicationId to `dev.runanywhere.aistudio`
- Changed versionCode to 1, versionName to 1.0.0

### 6. Android strings.xml
- Changed app name to "RunAnywhere AI Studio"

### 7. iOS Podfile
Added pods:
```ruby
pod 'NitroModules', :path => '../node_modules/react-native-nitro-modules'
pod 'RunAnywhereCore', :path => '../node_modules/@runanywhere/core'
pod 'RunAnywhereLlama', :path => '../node_modules/@runanywhere/llamacpp'
pod 'RunAnywhereONNX', :path => '../node_modules/@runanywhere/onnx'
```

### 8. App Icons
Copied from `sdks/examples/android/RunAnywhereAI/` sample app.

---

## Comparison: Expo Go vs RunAnywhere AI Studio

| Feature | Expo Go | RunAnywhere AI Studio |
|---------|---------|----------------------|
| Scan QR code | âœ… | âœ… |
| Load from Metro | âœ… | âœ… |
| expo-camera | âœ… | âœ… |
| expo-file-system | âœ… | âœ… |
| All 50+ Expo modules | âœ… | âœ… |
| Recent projects | âœ… | âœ… |
| Error overlay | âœ… | âœ… |
| Dev menu | âœ… | âœ… |
| @runanywhere/core | âŒ | âœ… |
| @runanywhere/llamacpp | âŒ | âœ… |
| @runanywhere/onnx | âŒ | âœ… |
| On-device LLM | âŒ | âœ… |
| On-device ML | âŒ | âœ… |

---

## What Developers Do

### In Their Replit/Cursor Project

```json
// package.json
{
  "dependencies": {
    "expo": "~54.0.0",
    "@runanywhere/core": "^0.16.11",
    "@runanywhere/llamacpp": "^0.16.11",
    "@runanywhere/onnx": "^0.16.11"
  }
}
```

### In Their App Code

```typescript
// App.tsx
import { LlamaCpp } from '@runanywhere/llamacpp';

export default function App() {
  const [response, setResponse] = useState('');
  
  const runAI = async () => {
    // This works because RunAnywhere AI Studio has the native binaries!
    await LlamaCpp.loadModel('/path/to/model.gguf');
    const result = await LlamaCpp.generate('Hello, AI!');
    setResponse(result);
  };

  return (
    <View>
      <Button title="Run AI" onPress={runAI} />
      <Text>{response}</Text>
    </View>
  );
}
```

### Run Flow

```bash
# Developer runs Metro
npx expo start

# Shows QR code - scan with RunAnywhere AI Studio
# App loads, RunAnywhere APIs work!
```

---

## Build Process

### Prerequisites
- Node.js 18+
- Yarn (workspace)
- Android Studio with NDK
- Xcode 15+

### Build Commands

```bash
# From expo-test root
cd /path/to/EXPO/expo-test

# Install all dependencies
yarn install

# Build Android
cd apps/runanywhere-ai-studio/android
./gradlew assembleRelease

# Build iOS
cd ../ios
pod install
xcodebuild -workspace Exponent.xcworkspace -scheme "Expo Go" -configuration Release
```

---

## Directory Structure

```
EXPO/expo-test/apps/runanywhere-ai-studio/
â”œâ”€â”€ android/
â”‚   â”œâ”€â”€ app/
â”‚   â”‚   â”œâ”€â”€ build.gradle          # â† Modified: namespace, applicationId
â”‚   â”‚   â””â”€â”€ src/main/res/
â”‚   â”‚       â”œâ”€â”€ mipmap-*/         # â† Replaced: RunAnywhere icons
â”‚   â”‚       â””â”€â”€ values/strings.xml # â† Modified: app name
â”‚   â”œâ”€â”€ expoview/
â”‚   â”‚   â””â”€â”€ build.gradle          # â† Modified: added RunAnywhere deps
â”‚   â””â”€â”€ settings.gradle           # â† Modified: added RunAnywhere modules
â”œâ”€â”€ ios/
â”‚   â””â”€â”€ Podfile                   # â† Modified: added RunAnywhere pods
â”œâ”€â”€ app.json                      # â† Modified: rebranded
â”œâ”€â”€ package.json                  # â† Modified: renamed, added deps
â””â”€â”€ INTEGRATION_GUIDE.md          # â† This file
```

---

## FAQ

### Q: Will apps made for Expo Go work in RunAnywhere AI Studio?

**Yes!** It's the same Expo kernel. Any app that works in Expo Go will work in RunAnywhere AI Studio.

### Q: Will RunAnywhere APIs work in regular Expo Go?

**No.** Expo Go doesn't have the native binaries. The app will crash if it tries to use `@runanywhere/llamacpp`.

### Q: Can developers use both Expo modules and RunAnywhere?

**Yes!** That's the whole point. They get the full Expo ecosystem PLUS on-device AI.

### Q: What about app size?

The native libraries add approximately:
- llama.cpp: ~5-10 MB per architecture
- ONNX Runtime: ~10-15 MB per architecture
- Total additional: ~15-25 MB

This is comparable to adding a few Expo modules.

---

## Next Steps

1. âœ… Copy expo-go app
2. âœ… Add RunAnywhere packages to package.json
3. âœ… Modify Android settings.gradle
4. âœ… Modify Android expoview/build.gradle
5. âœ… Modify iOS Podfile
6. âœ… Rebrand (name, bundle ID, icons)
7. ğŸ”„ Install dependencies and build
8. â³ Test on device
9. â³ Publish to app stores
